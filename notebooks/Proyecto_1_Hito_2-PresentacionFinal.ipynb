{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHCinED00NXrfhsTkWEk2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalpata/proyecto_aplicado_preservantes/blob/main/notebooks/Proyecto_1_Hito_2-PresentacionFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Baseline - Proyecto Aplicado: Preservantes\n",
        "\n",
        "En este notebook construimos el baseline de un sistema RAG usando un conjunto de PDFs\n",
        "sobre preservantes. Incluye:\n",
        "\n",
        "1. Carga e ingesta de PDFs\n",
        "2. Preprocesamiento b√°sico y chunking\n",
        "3. Generaci√≥n de embeddings\n",
        "4. Creaci√≥n de un vector store\n",
        "5. Retriever (similarity search)\n",
        "6. Benchmark (Precision@k sobre un set de preguntas)\n"
      ],
      "metadata": {
        "id": "5aDwAGIuz_1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Instalaci√≥n de librer√≠as (celda de c√≥digo)\n",
        "!pip install -q langchain langchain-community langchain-text-splitters \\\n",
        "               chromadb sentence-transformers pypdf\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9Qjmzf770Mw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Importaciones y configuraci√≥n b√°sica\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Para evaluaci√≥n b√°sica\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "\n",
        "# Para ver resultados\n",
        "from pprint import pprint\n"
      ],
      "metadata": {
        "id": "qg7uO2fN0jCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESETEAR TODO PARA PARTIR LIMPIO EN COLAB\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "# 1) Ir a /content\n",
        "%cd /content\n",
        "\n",
        "# 2) Borrar cualquier clone previo duplicado\n",
        "if os.path.exists(\"proyecto_aplicado_preservantes\"):\n",
        "    shutil.rmtree(\"proyecto_aplicado_preservantes\")\n",
        "    print(\"üóëÔ∏è Carpeta borrada: proyecto_aplicado_preservantes\")\n",
        "\n",
        "# 3) Clonar de nuevo desde tu GitHub\n",
        "!git clone https://github.com/nalpata/proyecto_aplicado_preservantes.git\n",
        "\n",
        "# 4) Entrar a la carpeta correcta\n",
        "%cd proyecto_aplicado_preservantes\n",
        "\n",
        "print(\"\\nüéâ Listo. Ahora estamos en el repo correcto sin duplicados.\")\n",
        "!ls\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "g7lcsJzC073x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta base del proyecto en Colab\n",
        "BASE_PATH = Path(\"/content/proyecto_aplicado_preservantes\")\n",
        "\n",
        "DATA_PDF_DIR = BASE_PATH / \"data\" / \"pdfs\"          # aqu√≠ PDFs de preservantes\n",
        "CHROMA_DIR   = BASE_PATH / \"chroma_preservantes\"   # carpeta donde se guardar√° el vector store\n",
        "\n",
        "BASE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "CHROMA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Base path:\", BASE_PATH)\n",
        "print(\"PDF dir:\", DATA_PDF_DIR)\n",
        "print(\"Chroma dir:\", CHROMA_DIR)\n"
      ],
      "metadata": {
        "id": "28Zh6odf0wx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Carga de documentos (ingesta de PDFs)\n",
        "def load_pdfs(pdf_dir: Path):\n",
        "    \"\"\"\n",
        "    Carga todos los PDFs de una carpeta usando LangChain.\n",
        "    Devuelve una lista de Documents.\n",
        "    \"\"\"\n",
        "    loader = DirectoryLoader(\n",
        "        str(pdf_dir),\n",
        "        glob=\"*.pdf\",\n",
        "        loader_cls=PyPDFLoader,\n",
        "        show_progress=True\n",
        "    )\n",
        "    docs = loader.load()\n",
        "    return docs\n",
        "\n",
        "raw_docs = load_pdfs(DATA_PDF_DIR)\n",
        "len(raw_docs), raw_docs[0]\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TzhEq3kj1Nbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Preprocesamiento\n",
        "def clean_metadata(docs):\n",
        "    \"\"\"\n",
        "    Normaliza  los metadatos: agrega un campo 'source'\n",
        "    y mantiene solo lo relevante.\n",
        "    \"\"\"\n",
        "    cleaned = []\n",
        "    for d in docs:\n",
        "        meta = d.metadata or {}\n",
        "        source = meta.get(\"source\", \"\")\n",
        "        # Nos quedamos con un metadata simple\n",
        "        new_meta = {\n",
        "            \"source\": source,\n",
        "            \"page\": meta.get(\"page\", None)\n",
        "        }\n",
        "        d.metadata = new_meta\n",
        "        cleaned.append(d)\n",
        "    return cleaned\n",
        "\n",
        "docs = clean_metadata(raw_docs)\n",
        "len(docs), docs[0].metadata\n"
      ],
      "metadata": {
        "id": "i0uqQciH1h7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chunking baseline**\n",
        "\n",
        "Usamos RecursiveCharacterTextSplitter con:\n",
        "- chunk_size = 800\n",
        "- chunk_overlap = 200\n",
        "\n"
      ],
      "metadata": {
        "id": "xQ7macp-2VBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Chunking\n",
        "##Usamos RecursiveCharacterTextSplitter como baseline.\n",
        "\n",
        "CHUNK_SIZE = 800\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "len(chunks), chunks[0]\n"
      ],
      "metadata": {
        "id": "prHZWuWd10br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##cu√°ntos PDFs y de qu√© archivo vienen los chunks\n",
        "from collections import Counter\n",
        "\n",
        "print(\"N¬∞ de documentos originales:\", len(raw_docs))\n",
        "print(\"Fuentes (PDFs) originales:\")\n",
        "for src in sorted({d.metadata.get(\"source\") for d in raw_docs}):\n",
        "    print(\" -\", src)\n",
        "\n",
        "print(\"\\nN¬∞ de chunks:\", len(chunks))\n",
        "print(\"N¬∞ de chunks por PDF:\")\n",
        "conteo = Counter(d.metadata.get(\"source\") for d in chunks)\n",
        "for src, c in conteo.items():\n",
        "    print(f\"{src}: {c}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GuJ2XgvvCq9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos chunking gerarquico porque los chunks no estan balanceados y se genera un pdf dominante"
      ],
      "metadata": {
        "id": "4V6clGR5Fcib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Uso chunking gerarquico\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from uuid import uuid4\n",
        "\n",
        "# Splitter de nivel alto (bloques grandes)\n",
        "high_level_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "# Splitter de nivel bajo (para el vector store)\n",
        "low_level_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=700,\n",
        "    chunk_overlap=150,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "def hierarchical_chunk(docs):\n",
        "    \"\"\"\n",
        "    1. Divide en bloques grandes (nivel 1)\n",
        "    2. Cada bloque grande se subdivide en chunks peque√±os (nivel 2)\n",
        "    3. A√±ade metadatos de jerarqu√≠a (parent_id, level1_index)\n",
        "    \"\"\"\n",
        "    level1_docs = high_level_splitter.split_documents(docs)\n",
        "\n",
        "    final_chunks = []\n",
        "    for idx, d in enumerate(level1_docs):\n",
        "        parent_id = str(uuid4())  # id √∫nico del bloque grande\n",
        "\n",
        "        # subdividir este bloque\n",
        "        sub_docs = low_level_splitter.split_documents([d])\n",
        "\n",
        "        for s in sub_docs:\n",
        "            meta = dict(s.metadata)\n",
        "            meta[\"parent_id\"] = parent_id\n",
        "            meta[\"level1_index\"] = idx\n",
        "            s.metadata = meta\n",
        "            final_chunks.append(s)\n",
        "\n",
        "    return final_chunks\n",
        "\n",
        "hier_chunks = hierarchical_chunk(docs)\n",
        "len(hier_chunks), hier_chunks[0].metadata\n"
      ],
      "metadata": {
        "id": "NdT2ix_4EbhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "BASE_PATH = Path(\"/content/proyecto_aplicado_preservantes\")\n",
        "CHROMA_HIER_DIR = BASE_PATH / \"chroma_preservantes_hier\"\n",
        "\n",
        "import shutil\n",
        "shutil.rmtree(CHROMA_HIER_DIR, ignore_errors=True)\n",
        "CHROMA_HIER_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "vector_store_hier = Chroma.from_documents(\n",
        "    documents=hier_chunks,\n",
        "    embedding=embeddings,                  # el mismo modelo multiling√ºe\n",
        "    persist_directory=str(CHROMA_HIER_DIR)\n",
        ")\n",
        "\n",
        "vector_store_hier.persist()\n",
        "print(\"Vector store HIER creado con\", vector_store_hier._collection.count(), \"documentos\")\n"
      ],
      "metadata": {
        "id": "b59Si2a2FPAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_hier = vector_store_hier.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 5, \"fetch_k\": 20}\n",
        ")\n"
      ],
      "metadata": {
        "id": "loYBMp6jHDhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inspeccionar_query_con(retriever, query: str, k: int = 5):\n",
        "    docs = retriever.invoke(query)[:k]\n",
        "    print(\"Query:\", query, \"\\n\")\n",
        "    for i, d in enumerate(docs, 1):\n",
        "        print(f\"--- Documento {i} ---\")\n",
        "        print(\"Source:\", d.metadata.get(\"source\"), \"| Page:\", d.metadata.get(\"page\"),\n",
        "              \"| level1_index:\", d.metadata.get(\"level1_index\"))\n",
        "        print(d.page_content[:500], \"...\\n\")\n",
        "\n",
        "inspeccionar_query_con(retriever_hier, \"¬øWhat are the antimicrobial effects of sodium benzoate, sodium nitrite, and potassium sorbate?\")\n"
      ],
      "metadata": {
        "id": "VjdAGP91HLu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo de embeddings**"
      ],
      "metadata": {
        "id": "brXykKpx2rlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_MODEL_NAME = \"sentence-transformers/distiluse-base-multilingual-cased-v2\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME\n",
        ")\n",
        "\n",
        "print(\"Modelo cargado:\", EMBEDDING_MODEL_NAME)\n"
      ],
      "metadata": {
        "id": "IiTsG4nA2jrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector Store**"
      ],
      "metadata": {
        "id": "MxIQZoms29VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHROMA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "#Cuando uso el jer√°rquico\n",
        "CHROMA_HIER_DIR.mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "tvh1gplgRCpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=str(CHROMA_DIR)\n",
        ")\n",
        "\n",
        "vector_store.persist()\n",
        "print(\"Vector store creado con\", vector_store._collection.count(), \"documentos\")\n"
      ],
      "metadata": {
        "id": "rAVAjXe022LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vector_store_hier = Chroma.from_documents(\n",
        "    documents=hier_chunks,    # chunks jer√°rquicos\n",
        "    embedding=embeddings      # mismo modelo multiling√ºe\n",
        ")\n",
        "\n",
        "print(\"Vector store jer√°rquico creado en memoria con:\",\n",
        "      vector_store_hier._collection.count(), \"chunks\")\n"
      ],
      "metadata": {
        "id": "vEXoW3lmSH5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retriever jerarquico**"
      ],
      "metadata": {
        "id": "tQP7iP_Z7Hmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retriever jer√°rquico\n",
        "retriever_hier = vector_store_hier.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 5, \"fetch_k\": 20}\n",
        ")\n",
        "\n",
        "query_ejemplo = \"¬øQu√© es un preservante y qu√© funci√≥n cumple en alimentos?\"\n",
        "resultados_hier = retriever_hier.invoke(query_ejemplo)\n",
        "\n",
        "len(resultados_hier), resultados_hier[0]\n"
      ],
      "metadata": {
        "id": "zDf5OUf36fKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, d in enumerate(resultados_hier, 1):\n",
        "    print(f\"\\n### Documento {i} ###\")\n",
        "    print(\"Source:\", d.metadata.get(\"source\"), \"| Page:\", d.metadata.get(\"page\"))\n",
        "    print(d.page_content[:300], \"...\\n\")\n"
      ],
      "metadata": {
        "id": "ExNn466_7TMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_retriever(retriever, eval_queries, k=5, nombre=\"Evaluaci√≥n\"):\n",
        "    print(f\"\\n=== Evaluando retriever: {nombre} ===\\n\")\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    for item in eval_queries:\n",
        "        query = item[\"query\"]\n",
        "        keywords = item[\"relevant_keywords\"]\n",
        "\n",
        "        # Recuperar documentos\n",
        "        docs = retriever.invoke(query)[:k]\n",
        "\n",
        "        # Precision@k manual\n",
        "        hits = 0\n",
        "        for doc in docs:\n",
        "            text = doc.page_content.lower()\n",
        "            if any(kw.lower() in text for kw in keywords):\n",
        "                hits += 1\n",
        "\n",
        "        precision = hits / k\n",
        "        scores.append(precision)\n",
        "\n",
        "        print(f\"Query: {query}\")\n",
        "        print(f\"Precision@{k}: {precision:.2f}\\n\")\n",
        "\n",
        "    print(f\"Precision@{k} promedio: {sum(scores)/len(scores):.2f}\")\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "a3Q5z1HYk0Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive RAG**"
      ],
      "metadata": {
        "id": "cTXJlKGa7iiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 5}\n",
        ")\n"
      ],
      "metadata": {
        "id": "XT1bpwM7jmXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Baseline: solo mostrar textos recuperados\n",
        "def show_retrieval(query: str, k: int = 5, retriever=retriever):\n",
        "    # Con LangChain nuevo el retriever se invoca as√≠:\n",
        "    docs = retriever.invoke(query)\n",
        "    docs = docs[:k]\n",
        "\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    for i, d in enumerate(docs, start=1):\n",
        "        print(f\"--- Documento {i} ---\")\n",
        "        print(\"Source:\", d.metadata.get(\"source\"), \"Page:\", d.metadata.get(\"page\"))\n",
        "        print(d.page_content[:500], \"...\")\n",
        "        print()\n",
        "\n",
        "# Prueba\n",
        "show_retrieval(\"Tipos de preservantes utilizados en bebidas\", retriever=retriever_hier)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DzTmLdl67kcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integramos un LLM para responder**"
      ],
      "metadata": {
        "id": "JeisbG5h9AvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-openai langchain-community openai tiktoken\n"
      ],
      "metadata": {
        "id": "_u_CVpbg9egb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-openai langchain-community langchain-text-splitters\n",
        "!pip install -q langchain-core\n",
        "!pip install -q langchain-experimental\n",
        "!pip install -q langchainhub\n",
        "!pip install -q lc-retrieval\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fOPmeegY-HRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n"
      ],
      "metadata": {
        "id": "GMeWfL_h_Ibi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Ingresa tu OPENAI_API_KEY: \")\n"
      ],
      "metadata": {
        "id": "gCAc7EqO_Lxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n"
      ],
      "metadata": {
        "id": "nvBeg2PA_bkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_rag(query: str, k: int = 5, retriever=retriever_hier):\n",
        "    # 1. Recuperar documentos relevantes\n",
        "    docs = retriever.invoke(query)\n",
        "    docs = docs[:k]\n",
        "\n",
        "    # 2. Construir el contexto a partir de los chunks\n",
        "    context = \"\\n\\n---\\n\\n\".join(d.page_content for d in docs)\n",
        "\n",
        "    # 3. Armar el prompt para el LLM\n",
        "    prompt = f\"\"\"\n",
        "Eres un asistente experto en preservantes de alimentos.\n",
        "Responde usando EXCLUSIVAMENTE la informaci√≥n del contexto.\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pregunta: {query}\n",
        "\n",
        "Respuesta en espa√±ol, clara y concisa:\n",
        "\"\"\"\n",
        "\n",
        "    # 4. Llamar al modelo\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    # 5. Mostrar resultado y fuentes\n",
        "    print(\"Pregunta:\", query)\n",
        "    print(\"\\n Respuesta:\\n\")\n",
        "    print(response.content)\n",
        "\n",
        "    print(\"\\n Fuentes:\")\n",
        "    for d in docs:\n",
        "        print(\"-\", d.metadata.get(\"source\"), \"| page\", d.metadata.get(\"page\"))\n"
      ],
      "metadata": {
        "id": "oLAzc9bgW5wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_rag(\"Tipos de preservantes utilizados en bebidas\", retriever=retriever_hier)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NrOhn50DADER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark  (Precision@k)**"
      ],
      "metadata": {
        "id": "TMTkYd5HAhcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_hier = vector_store_hier.as_retriever(\n",
        "    search_type=\"mmr\",          # b√∫squeda diversificada\n",
        "    search_kwargs={\n",
        "        \"k\": 5,                 # n√∫mero final de documentos que regresar√°\n",
        "        \"fetch_k\": 20           # n√∫mero de documentos que explora primero\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "ebOtmiSQXorF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_queries = [\n",
        "{\n",
        "  \"query\": \"¬øQu√© es un preservante antimicrobiano?\",\n",
        "  \"relevant_keywords\": [\n",
        "    \"preservante antimicrobiano\",\n",
        "    \"conservante antimicrobiano\",\n",
        "    \"inhibici√≥n microbiana\",\n",
        "    \"inhibe el crecimiento microbiano\",\n",
        "    \"sustancia antimicrobiana\",\n",
        "    \"agente antimicrobiano\",\n",
        "    \"inhibici√≥n de microorganismos\",\n",
        "\n",
        "    \"antimicrobial preservative\",\n",
        "    \"antimicrobial agent\",\n",
        "    \"microbial growth inhibition\",\n",
        "    \"inhibits microbial growth\"\n",
        "  ]\n",
        "},\n",
        "{\n",
        "  \"query\": \"¬øCu√°les son los factores que afectan la efectividad de los preservantes?\",\n",
        "  \"relevant_keywords\": [\n",
        "    \"efectividad de los preservantes\",\n",
        "    \"factores que afectan la efectividad\",\n",
        "    \"actividad de agua\",\n",
        "    \"aw\",\n",
        "    \"concentraci√≥n del conservante\",\n",
        "    \"concentraci√≥n inhibitoria\",\n",
        "    \"pKa del conservante\",\n",
        "    \"interacci√≥n con composici√≥n del alimento\",\n",
        "\n",
        "    \"preservative effectiveness\",\n",
        "    \"factors influencing preservative efficacy\",\n",
        "    \"water activity\",\n",
        "    \"aw value\",\n",
        "    \"preservative concentration\",\n",
        "    \"food composition interaction\",\n",
        "    \"minimum inhibitory concentration\"\n",
        "  ]\n",
        "},\n",
        "{\n",
        "  \"query\": \"¬øQu√© se entiende por vida √∫til de un alimento?\",\n",
        "  \"relevant_keywords\": [\n",
        "    \"vida √∫til del alimento\",\n",
        "    \"vida √∫til\",\n",
        "    \"deterioro microbiano\",\n",
        "    \"estabilidad del alimento\",\n",
        "    \"seguridad alimentaria\",\n",
        "    \"calidad durante el almacenamiento\",\n",
        "\n",
        "    \"shelf life\",\n",
        "    \"food shelf life\",\n",
        "    \"food spoilage\",\n",
        "    \"microbial spoilage\",\n",
        "    \"quality stability\",\n",
        "    \"storage stability\"\n",
        "  ]\n",
        "}\n",
        "]\n"
      ],
      "metadata": {
        "id": "_Vppu_vwY98m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_hier = evaluate_retriever(\n",
        "    retriever_hier,\n",
        "    eval_queries,\n",
        "    k=5,\n",
        "    nombre=\"Jer√°rquico (MMR + chunking estructural)\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "xaH9fAOOX6NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "def precision_at_k(query: str, retrieved_docs: List, keywords: List[str], k: int = 5):\n",
        "    \"\"\"\n",
        "    Calcula Precision@k verificando si los documentos recuperados contienen keywords relevantes.\n",
        "    \"\"\"\n",
        "    hits = 0\n",
        "    for doc in retrieved_docs[:k]:\n",
        "        text = doc.page_content.lower()\n",
        "        # Si alguna keyword aparece en el texto => HIT\n",
        "        if any(keyword.lower() in text for keyword in keywords):\n",
        "            hits += 1\n",
        "\n",
        "    return hits / k  # Precision@k\n",
        "\n",
        "\n",
        "def evaluate_retriever_precision(retriever, eval_queries, k: int = 5, nombre: str = \"Modelo\"):\n",
        "    \"\"\"\n",
        "    Aplica Precision@k a un conjunto de queries y muestra resultados.\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Evaluando retriever: {nombre} ===\\n\")\n",
        "\n",
        "    scores = []\n",
        "    for item in eval_queries:\n",
        "        query = item[\"query\"]\n",
        "        keywords = item[\"relevant_keywords\"]\n",
        "\n",
        "        # Recuperar documentos\n",
        "        retrieved = retriever.invoke(query)\n",
        "\n",
        "        # Calcular Prec@k\n",
        "        score = precision_at_k(query, retrieved, keywords, k)\n",
        "        scores.append(score)\n",
        "\n",
        "        print(f\"Query: {query}\")\n",
        "        print(f\"Precision@{k}: {score:.2f}\\n\")\n",
        "\n",
        "    print(f\"Precision@{k} promedio: {np.mean(scores):.2f}\")\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "g_jzkS3eZKUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_hier = evaluate_retriever_precision(\n",
        "    retriever_hier,\n",
        "    eval_queries,\n",
        "    k=5,\n",
        "    nombre=\"Jer√°rquico (MMR)\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "zDhMS1hyZO1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSIONES**\n",
        "\n",
        "Corpus heterog√©neo (ingl√©s/espa√±ol): Los documentos contienen conceptos relevantes en distintos idiomas, lo que afecta la recuperaci√≥n cuando la evaluaci√≥n depende de keywords √∫nicamente en espa√±ol o traducciones exactas.\n",
        "\n",
        "Evaluaci√≥n basada en coincidencia de palabras clave: Precision@k penaliza documentos que son relevantes conceptualmente, pero no contienen literalmente las palabras clave definidas.\n",
        "\n",
        "Preguntas conceptuales dif√≠ciles: Consultas de tipo ‚Äú¬øQu√© es‚Ä¶?‚Äù requieren definiciones expl√≠citas que pueden no aparecer como tal en el corpus o estar formuladas con vocabulario t√©cnico, reduciendo la recuperaci√≥n efectiva.\n",
        "\n",
        "Tama√±o y calidad del corpus: Aunque el corpus es valioso, varias fuentes no est√°n estructuradas pedag√≥gicamente y contienen tablas, f√≥rmulas o p√°rrafos extensos, lo que dificulta la segmentaci√≥n √≥ptima.\n",
        "\n",
        "**POSIBLES MEJORAS PARA SIGUENTE HITO**\n",
        "\n",
        "Mejorar los embeddings. Adoptar un modelo m√°s robusto y cient√≠fico multiling√ºe\n",
        "\n",
        "Optimizar el proceso de chunking: Usar chunking h√≠brido (estructura + sem√°ntica + tama√±o).\n",
        "\n",
        "Incluir metadatos expl√≠citos (subt√≠tulos, figuras, secciones) para mejorar contexto jer√°rquico.\n",
        "\n",
        "Mejorar la evaluaci√≥n: Expandir keywords con sin√≥nimos y variaciones t√©cnicas.\n",
        "\n"
      ],
      "metadata": {
        "id": "ISl_Iba9aqgv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkZx9CSIbP3a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}