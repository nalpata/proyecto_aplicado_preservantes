# RAG ‚Äì Hito 2 | Presentaci√≥n Final

Este repositorio implementa una soluci√≥n completa de **Retrieval-Augmented Generation (RAG)** que se ejecuta **localmente**, con una **interfaz de usuario en Streamlit** que permite visualizar y probar todo el pipeline de forma interactiva.

El objetivo del proyecto es demostrar, de manera modular y reproducible, las tres etapas fundamentales de un sistema RAG:
1. **Ingesta de documentos**
2. **Recuperaci√≥n de contexto**
3. **Generaci√≥n de respuestas con un LLM local**

---

## üß© Arquitectura general

La soluci√≥n est√° dise√±ada siguiendo un enfoque **modular**, donde cada componente del pipeline est√° desacoplado y puede evaluarse de forma independiente.

### Pipeline RAG
1. **Ingesta**
   - Carga de documentos PDF
   - Extracci√≥n de texto
   - Segmentaci√≥n en fragmentos (*chunking*)
   - Persistencia del √≠ndice

2. **Recuperaci√≥n**
   - Recuperaci√≥n basada en similitud vectorial
   - Recuperaci√≥n l√©xica con BM25
   - Estrategia h√≠brida (vector + BM25)

3. **Generaci√≥n**
   - Uso de un modelo de lenguaje local en formato GGUF
   - Generaci√≥n de respuestas restringidas exclusivamente al contexto recuperado

La interfaz Streamlit muestra visualmente estas tres etapas, permitiendo configurar par√°metros y observar los resultados de cada fase.

---

## üìÅ Estructura del repositorio

```text
‚îú‚îÄ‚îÄ app.py                 # Interfaz Streamlit
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ pdfs/              # Documentos PDF de entrada
‚îÇ   ‚îî‚îÄ‚îÄ indexes/           # √çndices persistidos del sistema
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuraci√≥n centralizada
‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py       # Ingesta y construcci√≥n del √≠ndice
‚îÇ   ‚îú‚îÄ‚îÄ retrieval.py       # Recuperaci√≥n de contexto
‚îÇ   ‚îú‚îÄ‚îÄ generation.py      # Generaci√≥n con LLM local
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Funciones auxiliares
‚îÇ
‚îî‚îÄ‚îÄ notebooks/             # Notebooks de experimentaci√≥n (opcional)
````

---

## ‚öôÔ∏è Requisitos

* Python 3.9 o superior
* Ejecuci√≥n local (no depende de APIs externas)
* Modelo de lenguaje local en formato **GGUF**

---

## üì¶ Instalaci√≥n

Clonar el repositorio y crear un entorno virtual:

```bash
python -m venv .venv
```

Activar el entorno:

* **Windows**

```bash
.venv\Scripts\activate
```

* **Linux / Mac**

```bash
source .venv/bin/activate
```

Instalar dependencias:

```bash
pip install -r requirements.txt
```

---

## ‚ñ∂Ô∏è Ejecuci√≥n de la aplicaci√≥n

1. Colocar los documentos PDF en la carpeta:

```text
data/pdfs/
```

2. Ejecutar la aplicaci√≥n Streamlit:

```bash
streamlit run app.py
```

3. En la interfaz:

   * Configurar rutas y par√°metros desde la barra lateral
   * Ingresar una pregunta y observar:

     * Contexto recuperado
     * Respuesta generada
     * Fuentes utilizadas

---

## üß† Modelo de lenguaje

El sistema utiliza un **LLM local en formato GGUF**, cargado din√°micamente desde la ruta configurada en la interfaz.

> **Nota:**
> El archivo del modelo no se incluye en el repositorio debido a su tama√±o.
> La ruta al modelo se especifica directamente en la interfaz Streamlit.

---

## üîÅ Reproducibilidad

* El proyecto es completamente reproducible en entorno local
* No requiere conexi√≥n a servicios externos
* Los √≠ndices generados se almacenan en `data/indexes/`
* La modularizaci√≥n permite modificar o extender cada etapa del pipeline

---

## üìå Observaciones finales

Este proyecto demuestra el funcionamiento end-to-end de un sistema RAG, haciendo √©nfasis en:

* Separaci√≥n clara de responsabilidades
* Transparencia del proceso de recuperaci√≥n
* Reducci√≥n de alucinaciones mediante generaci√≥n condicionada al contexto

```

---

---

## üìì Trabajo experimental y evaluaci√≥n (Notebook)

El notebook `Proyecto_1_Hito_2.ipynb` documenta el desarrollo completo del **Hito 2**, con foco en la **evaluaci√≥n y mejora de la etapa de recuperaci√≥n** dentro de un sistema RAG. A diferencia del Hito 1 (baseline), este trabajo se centra en **analizar las limitaciones del pipeline inicial y proponer mejoras fundamentadas**, evaluadas de forma sistem√°tica.

### 1. An√°lisis inicial del corpus y baseline

El trabajo comienza con la carga y exploraci√≥n de un corpus compuesto por m√∫ltiples art√≠culos acad√©micos sobre preservantes de alimentos. Durante esta etapa se identific√≥ un **desbalance estructural del corpus**, donde algunos documentos aportaban una cantidad significativamente mayor de fragmentos (*chunks*) que otros.

Este fen√≥meno, denominado en el notebook como **‚ÄúPDF dominante‚Äù**, genera un sesgo en la recuperaci√≥n: el sistema tiende a recuperar fragmentos repetidamente del mismo documento, aun cuando otros textos contienen informaci√≥n conceptualmente relevante.

Como punto de partida, se construy√≥ un **baseline RAG** que incluye:

* chunking est√°ndar,
* embeddings multiling√ºes,
* vector store,
* recuperaci√≥n por similitud,
* y evaluaci√≥n manual mediante **Precision@k**.

Este baseline se conserva como referencia para comparar todas las mejoras posteriores.

---

### 2. Chunking jer√°rquico: motivaci√≥n y dise√±o

Para mitigar el problema del PDF dominante, el notebook propone e implementa una estrategia de **chunking jer√°rquico**, inspirada en la necesidad de preservar estructura sem√°ntica sin perder granularidad.

El enfoque consta de dos niveles:

* **Nivel 1:** fragmentos grandes que representan unidades sem√°nticas amplias (contexto global).
* **Nivel 2:** sub-fragmentos m√°s peque√±os, optimizados para la recuperaci√≥n.

Cada chunk incluye metadatos jer√°rquicos (`parent_id`, `level1_index`), lo que permite:

* mejorar la diversidad de los documentos recuperados,
* mantener trazabilidad entre fragmentos,
* y facilitar extensiones posteriores (reranking, agrupaci√≥n por documento).

Este redise√±o busca equilibrar representatividad del corpus sin introducir heur√≠sticas manuales dependientes del dominio.

---

### 3. Embeddings y vector store

El notebook utiliza embeddings multiling√ºes (`distiluse-base-multilingual-cased-v2`), adecuados para un corpus que contiene documentos en m√°s de un idioma.

Sobre estos embeddings se construye un **vector store persistente con Chroma**, incluyendo una versi√≥n espec√≠fica para el chunking jer√°rquico. La persistencia del √≠ndice permite:

* reproducibilidad de los experimentos,
* comparaci√≥n directa entre configuraciones,
* y reutilizaci√≥n eficiente en fases posteriores del pipeline.

---

### 4. Estrategias de recuperaci√≥n y evaluaci√≥n comparativa

Con el nuevo esquema de chunking, se evaluaron distintas estrategias de recuperaci√≥n:

* **Similarity search (baseline)**
* **MMR (Maximal Marginal Relevance)**, con distintos valores de `k`, `fetch_k` y `lambda_mult`
* **BM25**
* **Estrategias h√≠bridas**
* **Query processing y expansi√≥n de consultas**
* **Reranking**

La evaluaci√≥n se realiz√≥ mediante **Precision@k**, definida manualmente a partir de un conjunto de consultas y keywords relevantes, permitiendo comparar de forma consistente todas las variantes.

Los resultados muestran que:

* el uso de MMR no genera mejoras significativas en este dominio espec√≠fico,
* el chunking jer√°rquico mejora la diversidad estructural, pero no garantiza mejoras m√©tricas por s√≠ solo,
* **el procesamiento y expansi√≥n de consultas es la t√©cnica que produce la mayor mejora observada en Precision@5**,
* las estrategias h√≠bridas y con reranking ofrecen los mejores resultados globales dentro del conjunto evaluado.

---

### 5. Generaci√≥n y trazabilidad (RAG-G)

Finalmente, el notebook integra un **modelo de lenguaje local** para la generaci√≥n de respuestas condicionadas al contexto recuperado. La generaci√≥n se dise√±a con un **prompt restrictivo**, que obliga al modelo a responder √∫nicamente con la informaci√≥n presente en los fragmentos recuperados, mitigando expl√≠citamente el riesgo de alucinaciones.

Cada respuesta generada se guarda junto con:

* los fragmentos utilizados,
* el documento de origen,
* y los identificadores de chunk,

lo que garantiza **trazabilidad completa** y facilita el an√°lisis posterior del comportamiento del sistema.

---

### 6. Relaci√≥n entre notebook y aplicaci√≥n Streamlit

El notebook cumple un rol **anal√≠tico y experimental**, donde se exploran m√∫ltiples variantes del sistema RAG y se comparan cuantitativamente sus resultados.

La aplicaci√≥n **Streamlit**, en cambio, implementa una **demo final, modular y reproducible**, que:

* refleja el pipeline conceptual trabajado en el notebook,
* permite ejecutar el sistema localmente,
* y muestra de forma clara las etapas de ingesta, recuperaci√≥n y generaci√≥n.

De esta forma, el notebook documenta el **proceso de investigaci√≥n y toma de decisiones**, mientras que la aplicaci√≥n presenta la **soluci√≥n final ejecutable**.

---


